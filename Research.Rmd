


```{r}
#To efficiently show bias-variance trade-offs, we need to choose the parameters that are not very complex.
#First, I tried to make dataset generally, without shiny so that it is easier to understand
#For linear model:
library(tidyverse)
set.seed(6.24)
n <- 250
a <- 5
b <- 0.5
epsilon <- 4 #noise level

x <- runif(n, min = 30, max = 60)

# Generate noise (error term)
e1 <- rnorm(n, mean = 0, sd = epsilon)
e2 <- rnorm(n, mean = 0, sd = epsilon)
e3 <- rnorm(n, mean = 0, sd = epsilon)
e4 <- rnorm(n, mean = 0, sd = epsilon)
e5 <- rnorm(n, mean = 0, sd = epsilon)
e6 <- rnorm(n, mean = 0, sd = epsilon)
e7 <- rnorm(n, mean = 0, sd = epsilon)
e8 <- rnorm(n, mean = 0, sd = epsilon)
e9 <- rnorm(n, mean = 0, sd = epsilon)
e10 <- rnorm(n, mean = 0, sd = epsilon)

#True function without noise:
fx = (b*x) + a #in form of y = mx+c 

#function with noise added:
y1 = fx+e1
y2 = fx+e2
y3 = fx+e3
y4 = fx+e4
y5 = fx+e5
y6 = fx+e6
y7 = fx+e7
y8 = fx+e8
y9 = fx+e9
y10 = fx+e10

#convert in data frame
toy_data <- data.frame(
  inp = x,
  true_form = fx,
  response1 = y1,
  response2 = y2,
  response3 = y3,
  response4 = y4,
  response5 = y5,
  response6 = y6,
  response7 = y7,
  response8 = y8,
  response9 = y9,
  response10 = y10
)

```

```{r}
set.seed(6.24)
n <- 250
a <- 5
b <- 0.5
c <- 0.76
epsilon <- 4 #noise level

x <- runif(n, min = 30, max = 60)

# Generate noise (error term)
e1 <- rnorm(n, mean = 0, sd = epsilon)
e2 <- rnorm(n, mean = 0, sd = epsilon)
e3 <- rnorm(n, mean = 0, sd = epsilon)
e4 <- rnorm(n, mean = 0, sd = epsilon)
e5 <- rnorm(n, mean = 0, sd = epsilon)
e6 <- rnorm(n, mean = 0, sd = epsilon)
e7 <- rnorm(n, mean = 0, sd = epsilon)
e8 <- rnorm(n, mean = 0, sd = epsilon)
e9 <- rnorm(n, mean = 0, sd = epsilon)
e10 <- rnorm(n, mean = 0, sd = epsilon)

fx = a + b * x + c * x^2

#function with noise added:
y1 = fx+e1
y2 = fx+e2
y3 = fx+e3
y4 = fx+e4
y5 = fx+e5
y6 = fx+e6
y7 = fx+e7
y8 = fx+e8
y9 = fx+e9
y10 = fx+e10

#convert in data frame
toy_data <- data.frame(
  inp = x,
  true_form = fx,
  response1 = y1,
  response2 = y2,
  response3 = y3,
  response4 = y4,
  response5 = y5,
  response6 = y6,
  response7 = y7,
  response8 = y8,
  response9 = y9,
  response10 = y10
)

```

```{r}
library(shiny)
  ui <- fluidPage(
  titlePanel("Bias-Variance Tradeoff Visualization"),
  
  sidebarLayout(
    sidebarPanel(
      selectInput("model_degree", "Select Polynomial Degree:", 
                  choices = 1:5, selected = 2),
      numericInput("epsilon", "Noise Level (epsilon):", value = 5, min = 0, step = 0.1),
      actionButton("generate", "Generate Data")
    ),
    
    mainPanel(
      plotOutput("biasVariancePlot"),
      tableOutput("resultsTable")
    )
  )
)

server <- function(input, output) {
generate_dataset <- function(n, a, b, epsilon, seed = NULL) {
    if (!is.null(seed)) set.seed(seed)
    x <- runif(n, min = -10, max = 10)
    e <- rnorm(n, mean = 0, sd = epsilon)
    y <- a + (b * x) + e
    data.frame(x = x, y = y)
  }
  
  fit_polynomial_model <- function(data, degree) {
    lm(y ~ poly(x, degree, raw = TRUE), data = data)
  }
```

```{r}
library(tidyverse)

# Simulate data
set.seed(2024)
a <- 3
b <- 0.87
c <- 0.5
n <- 100
x <- runif(n, min = -5, max = 5)
epsilon <- 1

e <- replicate(10, rnorm(n, mean = 0, sd = epsilon))
fx <- a + (b * x^2) + (c * x^3)
y <- fx + e

# Initialize vectors to store bias and variance
degrees <- 1:10
bias <- numeric(length(degrees))
variance <- numeric(length(degrees))

# Calculate bias and variance for each degree
for (degree in degrees) {
  predictions <- matrix(NA, nrow = n, ncol = 10)
  for (i in 1:10) {
    model <- lm(y[, i] ~ poly(x, degree))
    predictions[, i] <- predict(model, newdata = data.frame(x = x))
  }
  avg_predictions <- rowMeans(predictions)
  squared_bias <- (avg_predictions - fx)^2
  bias[degree] <- mean(squared_bias)
  variance[degree] <- mean(apply(predictions, 1, var))
}

# Create data frame for ggplot
bias_variance <- data.frame(
  Degree = rep(degrees, 2),
  Value = c(bias, variance),
  Metric = rep(c("Bias", "Variance"), each = length(degrees))
)

# Plot the results
ggplot(bias_variance, aes(x = factor(Degree), y = Value, fill = Metric)) +
  geom_bar(stat = "identity", position = "dodge", alpha = 0.8) +
  scale_fill_manual(values = c("Bias" = "skyblue", "Variance" = "lightpink")) +
  labs(title = "Bias and Variance by Polynomial Degree", x = "Polynomial Degree", y = "Value") +
  theme_minimal()

```
```{r}
library(ggplot2)
library(dplyr)

# Sample data
bar_data <- data.frame(
  Degree= c(1, 2 , 3),
  bias = c(1200, 1750, 1720),
  variance = c(8343, 8544, 8222)
)

# Define colors
colors <- c("Bias" = "skyblue", "Variance" = "lightpink")

# Create the plot
p <- ggplot(bar_data, aes(x = factor(Degree))) +
  geom_bar(aes(y = bias, fill = "Bias"), stat = "identity", position = "dodge", alpha = 0.8) +
  geom_bar(aes(y = variance / 10, fill = "Variance"), stat = "identity", position = "dodge", alpha = 0.8) + # Adjusted for scale
  scale_fill_manual(values = colors) +
  scale_y_continuous(
    name = "Bias",
    sec.axis = sec_axis(~.*10, name = "Variance")
  ) +
  labs(
    title = "Bias and Variance by Degree",
    x = "degree",
    fill = "Metric"
  ) +
  theme_minimal()

# Display the plot
print(p)
```

```{r}
set.seed(2024) #change to 2024

# simulate data
x <- runif(n = 100, min = 20, max = 40)   # input/predictor

e1 <- rnorm(n = 100, mean = 0, sd = 2)  # error
e2 <- rnorm(n = 100, mean = 0, sd = 2)  # error
e3 <- rnorm(n = 100, mean = 0, sd = 2)  # error
e4 <- rnorm(n = 100, mean = 0, sd = 2)  # error
e5 <- rnorm(n = 100, mean = 0, sd = 2)  # error
e6 <- rnorm(n = 100, mean = 0, sd = 2)  # error
e7 <- rnorm(n = 100, mean = 0, sd = 2)  # error
e8 <- rnorm(n = 100, mean = 0, sd = 2)  # error
e9 <- rnorm(n = 100, mean = 0, sd = 2)  # error
e10 <- rnorm(n = 100, mean = 0, sd = 2)  # error

a <- 3
b <- 0.87
fx <- a + (b * x)  # true function

y1 <- fx + e1    # observed responses
y2 <- fx + e2    # observed responses
y3 <- fx + e3    # observed responses
y4 <- fx + e4    # observed responses
y5 <- fx + e5    # observed responses
y6 <- fx + e6    # observed responses
y7 <- fx + e7    # observed responses
y8 <- fx + e8    # observed responses
y9 <- fx + e9    # observed responses
y10 <- fx + e10    # observed responses

toy_data <- data.frame(inp = x, true_form = fx, response1 = y1, response2 = y2, response3 = y3, response4 = y4, response5 = y5,
                       response6 = y6, response7 = y7, response8 = y8, response9 = y9, response10=y10)

ggplot(data = toy_data) + geom_point(aes(x = inp, y = response1))   # one of the data plots for the shiny app

d = 1   # linear fit
d1 = 2
d2 = 3
d3 = 4

m1 <- lm(response1 ~ poly(inp, degree = d, raw = TRUE), data = toy_data)   # model for the first replicated dataset
y_hat_1 <- predict(m1, newdata = data.frame(inp = toy_data$inp))
# y_hat_1 <- predict(m1, newdata = data.frame(inp = test_dat$inp))

# replicate the above process for 10 times

m2 <- lm(response2 ~ poly(inp, degree = d, raw = TRUE), data = toy_data)   # model for the second replicated dataset
y_hat_2 <- predict(m2, newdata = data.frame(inp = toy_data$inp))

m3 <- lm(response3 ~ poly(inp, degree = d, raw = TRUE), data = toy_data)
y_hat_3<- predict(m3, newdata = data.frame(inp = toy_data$inp))

m4 <- lm(response4 ~ poly(inp, degree = d, raw = TRUE), data = toy_data)
y_hat_4<- predict(m4, newdata = data.frame(inp = toy_data$inp))

m5 <- lm(response5 ~ poly(inp, degree = d, raw = TRUE), data = toy_data)
y_hat_5<- predict(m5, newdata = data.frame(inp = toy_data$inp))

m6 <- lm(response6 ~ poly(inp, degree = d, raw = TRUE), data = toy_data)
y_hat_6<- predict(m6, newdata = data.frame(inp = toy_data$inp))

m7 <- lm(response7 ~ poly(inp, degree = d, raw = TRUE), data = toy_data)
y_hat_7<- predict(m7, newdata = data.frame(inp = toy_data$inp))

m8 <- lm(response8 ~ poly(inp, degree = d, raw = TRUE), data = toy_data)
y_hat_8<- predict(m8, newdata = data.frame(inp = toy_data$inp))

m9 <- lm(response9 ~ poly(inp, degree = d, raw = TRUE), data = toy_data)
y_hat_9<- predict(m9, newdata = data.frame(inp = toy_data$inp))

m10 <- lm(response10 ~ poly(inp, degree = d, raw = TRUE), data = toy_data)
y_hat_10<- predict(m10, newdata = data.frame(inp = toy_data$inp))

m1d <- lm(response1 ~ poly(inp, degree = d1, raw = TRUE), data = toy_data)  
y_hat_1d <- predict(m1d, newdata = data.frame(inp = toy_data$inp))

m2d <- lm(response2 ~ poly(inp, degree = d1, raw = TRUE), data = toy_data)
y_hat_2d <- predict(m2d, newdata = data.frame(inp = toy_data$inp))

m3d <- lm(response3 ~ poly(inp, degree = d1, raw = TRUE), data = toy_data)
y_hat_3d<- predict(m3d, newdata = data.frame(inp = toy_data$inp))

m4d <- lm(response4 ~ poly(inp, degree = d1, raw = TRUE), data = toy_data)
y_hat_4d<- predict(m4d, newdata = data.frame(inp = toy_data$inp))

m5d <- lm(response5 ~ poly(inp, degree = d1, raw = TRUE), data = toy_data)
y_hat_5d<- predict(m5d, newdata = data.frame(inp = toy_data$inp))

m6d <- lm(response6 ~ poly(inp, degree = d1, raw = TRUE), data = toy_data)
y_hat_6d<- predict(m6d, newdata = data.frame(inp = toy_data$inp))

m7d <- lm(response7 ~ poly(inp, degree = d1, raw = TRUE), data = toy_data)
y_hat_7d<- predict(m7d, newdata = data.frame(inp = toy_data$inp))

m8d <- lm(response8 ~ poly(inp, degree = d1, raw = TRUE), data = toy_data)
y_hat_8d<- predict(m8d, newdata = data.frame(inp = toy_data$inp))

m9d <- lm(response9 ~ poly(inp, degree = d1, raw = TRUE), data = toy_data)
y_hat_9d<- predict(m9d, newdata = data.frame(inp = toy_data$inp))

m10d <- lm(response10 ~ poly(inp, degree = d1, raw = TRUE), data = toy_data)
y_hat_10d<- predict(m10d, newdata = data.frame(inp = toy_data$inp))

 

df_preds <- data.frame(y_hat_1 = y_hat_1, y_hat_2 = y_hat_2, y_hat_3 = y_hat_3, y_hat_4 = y_hat_4, y_hat_5 = y_hat_5, y_hat_6 = y_hat_6, y_hat_7 = y_hat_7, y_hat_8 = y_hat_8, y_hat_9 = y_hat_9, y_hat_10 = y_hat_10 )    # you should have ten columns instead of 2


# bias squared calculation
# 1
E_y_hat <- apply(df_preds, 1, mean)
# 2 and 3
bias_squared <- (E_y_hat - toy_data$true_form)^2
# 4
mean(bias_squared)


# variance calculation
# 1
V_y_hat <- apply(df_preds, d, var)
# 2
mean(V_y_hat)


bias_var_df <- data.frame(degree = d, bias_sq = mean(bias_squared), variance = mean(V_y_hat))

# create a dataset/matrix of each set y values (dimension - number of data points n x number of replications 10)

```
```{r}
m1d <- lm(response1 ~ poly(inp, degree = d1, raw = TRUE), data = toy_data)  
y_hat_1d <- predict(m1d, newdata = data.frame(inp = toy_data$inp))

m2d <- lm(response2 ~ poly(inp, degree = d1, raw = TRUE), data = toy_data)
y_hat_2d <- predict(m2d, newdata = data.frame(inp = toy_data$inp))

m3d <- lm(response3 ~ poly(inp, degree = d1, raw = TRUE), data = toy_data)
y_hat_3d<- predict(m3d, newdata = data.frame(inp = toy_data$inp))

m4d <- lm(response4 ~ poly(inp, degree = d1, raw = TRUE), data = toy_data)
y_hat_4d<- predict(m4d, newdata = data.frame(inp = toy_data$inp))

m5d <- lm(response5 ~ poly(inp, degree = d1, raw = TRUE), data = toy_data)
y_hat_5d<- predict(m5d, newdata = data.frame(inp = toy_data$inp))

m6d <- lm(response6 ~ poly(inp, degree = d1, raw = TRUE), data = toy_data)
y_hat_6d<- predict(m6d, newdata = data.frame(inp = toy_data$inp))

m7d <- lm(response7 ~ poly(inp, degree = d1, raw = TRUE), data = toy_data)
y_hat_7d<- predict(m7d, newdata = data.frame(inp = toy_data$inp))

m8d <- lm(response8 ~ poly(inp, degree = d1, raw = TRUE), data = toy_data)
y_hat_8d<- predict(m8d, newdata = data.frame(inp = toy_data$inp))

m9d <- lm(response9 ~ poly(inp, degree = d1, raw = TRUE), data = toy_data)
y_hat_9d<- predict(m9d, newdata = data.frame(inp = toy_data$inp))

m10d <- lm(response10 ~ poly(inp, degree = d1, raw = TRUE), data = toy_data)
y_hat_10d<- predict(m10d, newdata = data.frame(inp = toy_data$inp))

df_preds1 <- data.frame(y_hat_1d = y_hat_1d, y_hat_2d = y_hat_2d, y_hat_3d = y_hat_3d, y_hat_4d = y_hat_4d, y_hat_5d = y_hat_5d, y_hat_6d = y_hat_6d, y_hat_7d = y_hat_7d, y_hat_8d = y_hat_8d, y_hat_9d = y_hat_9d, y_hat_10d = y_hat_10d)

# bias squared calculation
# 1
E_y_hat <- apply(df_preds1, 1, mean)
# 2 and 3
bias_squared <- (E_y_hat - toy_data$true_form)^2
# 4
mean(bias_squared)


# variance calculation
# 1
V_y_hat <- apply(df_preds1, d1, var)
# 2
mean(V_y_hat)


bias_var_df1 <- data.frame(degree = d1, bias_sq = mean(bias_squared), variance = mean(V_y_hat))

```
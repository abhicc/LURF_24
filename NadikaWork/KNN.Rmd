

```{r}
library(ggplot2)
library(FNN)

set.seed(2024)

# Simulate data
x <- runif(n = 100, min = 20, max = 40)   # input/predictor

# Generate 500 sets of errors with more variability
errors <- matrix(rnorm(100 * 500, mean = 0, sd = 2), nrow = 100, ncol = 500)
a <- 3
b <- 0.87
c <- 0.05  # Define c for the cubic term
fx <- a + (b * x^2) + (c * x^3)  # true function

fx <- a + (b * x) + (c * sin(x))  # true function

# Generate observed responses
responses <- fx + errors

# Create a data frame
training_data <- data.frame(inp = x, true_form = fx, responses)

set.seed(2025)
xtest <- runif(n = 100, min = 20, max = 40)
error_test <- rnorm(n = 100, mean = 0, sd = 2)
fxtest <- a + (b * xtest^2) + (c * xtest^3)
response_test <- fxtest + error_test

# Create test data frame
test_data <- data.frame(inp = xtest, true_form = fxtest, response = response_test)

# Rename response columns for easier reference
colnames(training_data)[3:(3 + 499)] <- paste0("response", 1:500)

# Plot one of the data sets for visualization
ggplot(data = training_data) + 
  geom_point(aes(x = inp, y = response1)) +
  labs(title = "Simulated Data", x = "Input", y = "Response")

# K values to fit
ks <- 1:6
ks <- 3:20

# Initialize a data frame to store bias and variance for each K
bias_var_df <- data.frame(k = integer(), bias_sq = numeric(), variance = numeric(), training_mse = numeric(), test_mse = numeric())

for (k in ks) {
  # Store predictions for each K
  preds <- matrix(nrow = 100, ncol = 500)
  training_mse_list <- numeric(500)
  
  for (i in 1:500) {
    train_matrix <- as.matrix(training_data$inp)
    test_matrix <- as.matrix(test_data$inp)
    train_responses <- training_data[[paste0("response", i)]]
    
    model_knn <- knn.reg(train = train_matrix, test = train_matrix, y = train_responses, k = k)$pred
    preds[, i] <- knn.reg(train = train_matrix, test = test_matrix, y = train_responses, k = k)$pred
    training_preds <- model_knn
    training_mse_list[i] <- mean((train_responses - training_preds)^2)
    # Predict for training data
    train_preds <- knn.reg(train = train_matrix, test = train_matrix, y = train_responses, k = k)$pred
    # Predict for test data
    test_preds <- knn.reg(train = train_matrix, test = test_matrix, y = train_responses, k = k)$pred
    
    preds[, i] <- test_preds
    training_mse_list[i] <- mean((train_responses - train_preds)^2)
  }
  
  # Calculate bias squared
  E_y_hat <- apply(preds, 1, mean)
  bias_squared <- (E_y_hat - test_data$true_form)^2
  mean_bias_squared <- mean(bias_squared)
  
  # Calculate variance
  V_y_hat <- apply(preds, 1, var)
  mean_variance <- mean(V_y_hat)
  
  # Calculate test MSE
  test_mse <- mean_bias_squared + mean_variance + 2^2
  
  # Calculate mean training MSE
  mean_training_mse <- mean(training_mse_list)
  
  # Append results to data frame
  bias_var_df <- rbind(bias_var_df, data.frame(k = k, bias_sq = mean_bias_squared, variance = mean_variance, training_mse = mean_training_mse, test_mse = test_mse))
}

print(bias_var_df)


```

```{r}
library(ggplot2)
library(class)
```

```{r}
library(ggplot2)
library(FNN)

set.seed(2024)

# Simulate data
x <- runif(n = 100, min = 20, max = 40)   # input/predictor

# Generate 500 sets of errors with more variability
errors <- matrix(rnorm(100 * 500, mean = 0, sd = 2), nrow = 100, ncol = 500)
a <- 3
b <- 0.87
c <- 0.05  # Define c for the cubic term
fx <- a + (b * x) + (c * sin(x))  # true function

# Generate observed responses
responses <- fx + errors

# Create a data frame
training_data <- data.frame(inp = x, true_form = fx, responses)

set.seed(2025)
xtest <- runif(n = 100, min = 20, max = 40)
error_test <- rnorm(n = 100, mean = 0, sd = 2)
fxtest <- a + (b * xtest^2) + (c * xtest^3)
response_test <- fxtest + error_test

# Create test data frame
test_data <- data.frame(inp = xtest, true_form = fxtest, response = response_test)

# Rename response columns for easier reference
colnames(training_data)[3:(3 + 499)] <- paste0("response", 1:500)

# Define the K value
k <- 3  # You can choose any K value, here we use 3 for illustration

# Generate a sequence of input values with a step of 0.01
x_seq <- seq(20, 40, by = 0.01)

# Create a matrix for the sequence of input values
x_seq_matrix <- matrix(x_seq, ncol = 1)

# Predict responses using KNN for each value in the sequence
pred_values <- knn.reg(train = as.matrix(training_data$inp), test = x_seq_matrix, y = training_data$response1, k = k)$pred

# Create a data frame for plotting
plot_data <- data.frame(inp = x_seq, predicted = pred_values)

# Plot the predictions in a step-like manner
ggplot() + 
  geom_step(data = plot_data, aes(x = inp, y = predicted), direction = "hv") +
  labs(title = "KNN Model Predictions", x = "Input", y = "Predicted Response") +
  geom_point(data = training_data, aes(x = inp, y = response1), color = "red", alpha = 0.5) +
  theme_minimal()

```


```{r}
library(ggplot2)
library(FNN)

set.seed(2024)

# Simulate data
x <- runif(n = 100, min = 20, max = 40)   # input/predictor

# Generate 500 sets of errors with more variability
errors <- matrix(rnorm(100 * 500, mean = 0, sd = 2), nrow = 100, ncol = 500)
a <- 3
b <- 0.87
c <- 0.05  # Define c for the cubic term
fx <- a + (b * x^2) + (c * x^3)  # true function

fx <- a + (b * x) + (c * sin(x))  # true function

# Generate observed responses
responses <- fx + errors

# Create a data frame
training_data <- data.frame(inp = x, true_form = fx, responses)

set.seed(2025)
xtest <- runif(n = 100, min = 20, max = 40)
error_test <- rnorm(n = 100, mean = 0, sd = 2)
fxtest <- a + (b * xtest^2) + (c * xtest^3)
response_test <- fxtest + error_test

# Create test data frame
test_data <- data.frame(inp = xtest, true_form = fxtest, response = response_test)

# Rename response columns for easier reference
colnames(training_data)[3:(3 + 499)] <- paste0("response", 1:500)

# Plot one of the data sets for visualization
ggplot(data = training_data) + 
  geom_point(aes(x = inp, y = response1)) +
  labs(title = "Simulated Data", x = "Input", y = "Response")

# K values to fit
ks <- 1:6

# Initialize a data frame to store bias and variance for each K
bias_var_df <- data.frame(k = integer(), bias_sq = numeric(), variance = numeric(), training_mse = numeric(), test_mse = numeric())

for (k in ks) {
  # Store predictions for each K
  preds <- matrix(nrow = 100, ncol = 500)
  training_mse_list <- numeric(500)
  
  for (i in 1:500) {
    model_knn <- knn(train = as.matrix(training_data$inp), test = as.matrix(training_data$inp), cl = training_data[[paste0("response", i)]], k = k)
    preds[, i] <- as.numeric(knn(train = as.matrix(training_data$inp), test = as.matrix(test_data$inp), cl = training_data[[paste0("response", i)]], k = k))
    training_preds <- as.numeric(model_knn)
    training_mse_list[i] <- mean((training_data[[paste0("response", i)]] - training_preds)^2)
  }
  
  # Calculate bias squared
  E_y_hat <- apply(preds, 1, mean)
  bias_squared <- (E_y_hat - test_data$true_form)^2
  mean_bias_squared <- mean(bias_squared)
  
  # Calculate variance
  V_y_hat <- apply(preds, 1, var)
  mean_variance <- mean(V_y_hat)
  
  # Calculate test MSE using the theoretical formula
  test_mse <- mean_bias_squared + mean_variance + 2^2
  
  # Calculate mean training MSE
  mean_training_mse <- mean(training_mse_list)
  
  # Append results to data frame
  bias_var_df <- rbind(bias_var_df, data.frame(k = k, bias_sq = mean_bias_squared, variance = mean_variance, training_mse = mean_training_mse, test_mse = test_mse))
}

print(bias_var_df)

```
=======
# Define the K value
k <- 3  # You can choose any K value, here we use 3 for illustration

# Generate a sequence of input values with a step of 0.01
x_seq <- seq(20, 40, by = 0.01)

# Create a matrix for the sequence of input values
x_seq_matrix <- matrix(x_seq, ncol = 1)

# Predict responses using KNN for each value in the sequence
pred_values <- knn.reg(train = as.matrix(training_data$inp), test = x_seq_matrix, y = training_data$response1, k = k)$pred

# Create a data frame for plotting
plot_data <- data.frame(inp = x_seq, predicted = pred_values)

# Plot the predictions in a step-like manner
ggplot() + 
  geom_step(data = plot_data, aes(x = inp, y = predicted), direction = "hv") +
  labs(title = "KNN Model Predictions", x = "Input", y = "Predicted Response") +
  geom_point(data = training_data, aes(x = inp, y = response1), color = "red", alpha = 0.5) +
  theme_minimal()

```


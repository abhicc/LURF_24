
```{r}
library(ggplot2)
library(rpart)

set.seed(2024)

x <- runif(n = 100, min = -5, max = 5)

errors <- matrix(rnorm(100 * 500, mean = 0, sd = 2), nrow = 100, ncol = 500)
a <- 3
b <- 0.87
c <- 0.05  
fx <- a + (b * x^2) + (c * x^3)  # true function

# Generate observed responses
responses <- fx + errors

# Create a data frame
training_data <- data.frame(inp = x, true_form = fx, responses)

set.seed(2025)
xtest <- runif(n = 100, min = -5, max = 5)
error_test <- rnorm(n = 100, mean = 0, sd = 2)
fxtest <- a + (b * xtest^2) + (c * xtest^3)
response_test <- fxtest + error_test

# Create test data frame
test_data <- data.frame(inp = xtest, true_form = fxtest, response = response_test)

colnames(training_data)[3:(3 + 499)] <- paste0("response", 1:500)

# Plot one of the data sets for visualization
ggplot(data = training_data) + 
  geom_point(aes(x = inp, y = response1)) +
  geom_line(aes(x = inp, y = true_form), color = "blue") +
  labs(title = "Simulated Data", x = "Input", y = "Response")

# Fit model and calculate bias-variance 
bias_var_df <- data.frame(tree_size = integer(), bias_sq = numeric(), variance = numeric(), training_mse = numeric(), test_mse = numeric())

tree_sizes <- 2:6  

for (size in tree_sizes) {
  preds <- matrix(nrow = 100, ncol = 500)
  training_mse_list <- numeric(500)
  
  for (i in 1:500) {
    response_column <- paste0("response", i)
    
    model_tree <- rpart(as.formula(paste(response_column, "~ inp")), data = training_data, 
                        control = rpart.control(maxdepth = size, cp = 0, xval = 0, minbucket = 5))
    
    
# Predict on test data
    preds[, i] <- predict(model_tree, newdata = test_data)
    
  # Predict on training data and calculate training MSE
    training_preds <- predict(model_tree, newdata = training_data)
    training_mse_list[i] <- mean((training_data[[response_column]] - training_preds)^2)
  }
  
  # Calculate bias squared
  E_y_hat <- rowMeans(preds)
  bias_squared <- (E_y_hat - test_data$true_form)^2
  mean_bias_squared <- mean(bias_squared)
  
  # Calculate variance
  V_y_hat <- apply(preds, 1, var)
  mean_variance <- mean(V_y_hat)
  
  # Calculate test MSE
  test_mse <- mean_bias_squared + mean_variance + 2^2
  
  # Calculate mean training MSE
  mean_training_mse <- mean(training_mse_list)
  
  # data frame
  bias_var_df <- rbind(bias_var_df, data.frame(tree_size = size, bias_sq = mean_bias_squared, variance = mean_variance, training_mse = mean_training_mse, test_mse = test_mse))
}

print(bias_var_df)

# Plot predictions for tree size 2
tree_size <- 2

# Generate a sequence of input values with a step of 0.01
x_seq <- seq(-5, 5, by = 0.01)

# Create a data frame for the sequence of input values
x_seq_df <- data.frame(inp = x_seq)

# Calculate true function values for the sequence
fx_seq <- a + (b * x_seq^2) + (c * x_seq^3)

# Predict responses
model_tree <- rpart(response1 ~ inp, data = training_data, control = rpart.control(maxdepth = tree_size, cp = 0, xval = 0, minbucket = 5))
pred_values <- predict(model_tree, newdata = x_seq_df)

plot_data <- data.frame(inp = x_seq, predicted = pred_values, true_form = fx_seq)

# Plot the predictions
ggplot() + 
  geom_step(data = plot_data, aes(x = inp, y = predicted), direction = "hv") +
  geom_line(data = plot_data, aes(x = inp, y = true_form), color = "blue") + # Plot true function
  labs(title = paste("Regression Tree Model Predictions (Tree Size =", tree_size, ")"), x = "Input", y = "Predicted Response") +
  geom_point(data = training_data, aes(x = inp, y = response1), color = "red", alpha = 0.5) +
  theme_minimal()

```

